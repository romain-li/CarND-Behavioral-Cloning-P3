{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning\n",
    "\n",
    "---\n",
    "\n",
    "**Behavioral Cloning Project**\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "- Use the simulator to collect data of good driving behavior\n",
    "- Build, a convolution neural network in Keras that predicts steering angles from images\n",
    "- Train and validate the model with a training and validation set\n",
    "- Test that the model successfully drives around track one without leaving the road\n",
    "- Summarize the results with a written report\n",
    "\n",
    "---\n",
    "\n",
    "## Required Files\n",
    "\n",
    "### 1. Are all required files submitted?\n",
    "\n",
    "- `model.py` Code to training the model.\n",
    "- `drive.py` Code to driving the car.\n",
    "- `model.h5` Trained network data.\n",
    "- `writeup_report` This notebook.\n",
    "- `video.mp4` A video recording of my car.\n",
    "\n",
    "## Quality of Code\n",
    "\n",
    "### 1. Is the code functional?\n",
    "\n",
    "You can run the code by run\n",
    "\n",
    "```sh\n",
    "python drive.py model.h5\n",
    "```\n",
    "\n",
    "### 2. Is the code usable and readable?\n",
    "\n",
    "My code has the generator function named `generator`, it store the csv data in memory and read the image data when training the model.  \n",
    "It also contains comments to explain each step and some functions.\n",
    "\n",
    "## Model Architecture and Training Strategy\n",
    "\n",
    "### 1. Has an appropriate model architecture been employed for the task?\n",
    "\n",
    "My model is based on VGGNet, it has the convolution layers and RELU layers,  \n",
    "and I've added 3 layers at the first of network:\n",
    "\n",
    "```python\n",
    "    model.add(Cropping2D(cropping=((64, 24), (0,0)), input_shape=(160, 320, 3)))\n",
    "    model.add(Lambda(lambda x: (x / 127.5) - 1, input_shape=(72, 320, 3)))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 4)))\n",
    "```\n",
    "\n",
    "They normalize the data in the model.\n",
    "\n",
    "### 2. Has an attempt been made to reduce overfitting of the model?\n",
    "\n",
    "Based on VGGNet, after every pooling layer and activation layer, there are a dropout layer to reduce overfitting.\n",
    "\n",
    "### 3. Have the model parameters been tuned appropriately?\n",
    "\n",
    "Admin optimizer used, it's really easy to use.\n",
    "\n",
    "### 4. Is the training data chosen appropriately?\n",
    "\n",
    "I've drived for:\n",
    "\n",
    "- Two laps in the center of road.\n",
    "- One lap of recovery driving from the sides.\n",
    "- If the trained car drive out of road, get more samples at this position. \n",
    "\n",
    "## Architecture and Training Documentation\n",
    "\n",
    "### 1. Is the solution design documented?\n",
    "\n",
    "My model is based on VGGNet because I think in this case, the data is different and the data set is large. And the VGGNet can detect all the features in the images.  \n",
    "\n",
    "First, I've added three layers in the top of network,\n",
    "\n",
    "- Cropping2D: Reduce the image size and keep the helpful data.\n",
    "- Lambda: Normalize data.\n",
    "- AveragePooling2D: Further reduce the image size, like `cv2.resize` but it's in the network.\n",
    "\n",
    "![Cropping Image](notebook_images/cropping1.png)\n",
    "![Cropping Image](notebook_images/cropping2.png)\n",
    "![Cropping Image](notebook_images/cropping3.png)\n",
    "\n",
    "And then, I've changed the bottom of full connection layers to adptive this project: 43 classes.  \n",
    "But the result isn't very well because the predict result is linear, but the classes is discrete.  \n",
    "So I've changed the last layer to a tanh, it will generate the result in range (-1, 1), lucky, most the steering angle are in this range. So I cut the steering angle in samples (in `def process_angle(angle, speed)` function), and used the result of tanh activation directly, use `mse` for the loss function.\n",
    "\n",
    "When I training the model ,I found that the model like predict the angle near the `camera_correction` parameter, even when turning rather than correcting position, certainly, it will get the less loss.  \n",
    "I think it's caused by the count of zero steering samples, so I've droped some zero samples:\n",
    "\n",
    "```python\n",
    "# Drop half of 0 steering samples\n",
    "if float(row[6]) != 0 and random.random() < 0.5:\n",
    "    samples.append(row)\n",
    "```\n",
    "\n",
    "And then, I've added more samples at the bad driving position, add convolution layer or tune the features in every convlotion layer when I think the model forgot some knowledge.\n",
    "\n",
    "At last, I get a good model that the car tune to the correct direction in everywhere of the road.  \n",
    "But my car still can't drive safely over one lap, I found that because the understeer.  \n",
    "Then, I have try to modified the `drive.py` to change the drive strategy.\n",
    "\n",
    "\n",
    "Use 50% of the last steering angle to smooth the driving, and counter the understeer, because it will enlarge the steering angle when continuous turning.  \n",
    "```python\n",
    "# smooth steering\n",
    "steering_angle = self.last_steering_angle * 0.5 + steering_angle\n",
    "self.last_steering_angle = steering_angle\n",
    "```\n",
    "\n",
    "If the car wants steering a big angle, brake like a human. (I've increase the desired speed because it's too slow for testing)  \n",
    "*I've tried to predict the steering angle, threshold speed (brake) in model at the same time. But it's hardly to balance their weights for the loss function.*  \n",
    "```python\n",
    "if abs(steering_angle) > 0.05:\n",
    "    steering_angle = steering_angle * 2\n",
    "    controller.set_desired(set_speed / 2)\n",
    "else:\n",
    "    controller.set_desired(set_speed)\n",
    "```\n",
    "\n",
    "I have change the training code to train the model epoch by epoch, the validation loss always increase at the third of fourth time.  \n",
    "```python\n",
    "if os.path.exists(FLAGS.model):\n",
    "    model = load_model(FLAGS.model)\n",
    "else:\n",
    "    model = CNN()\n",
    "```\n",
    "\n",
    "At last, my car can run over one lap.\n",
    "\n",
    "\n",
    "### 2. Is the model architecture documented?\n",
    "\n",
    "My final model is like this:  \n",
    "*You can also see `def CNN()` in the code.*\n",
    "\n",
    "```\n",
    "    +--------------+\n",
    "    |   Cropping   |\n",
    "    +--------------+\n",
    "           |\n",
    "+----------------------+\n",
    "| Normalization Lambda |\n",
    "+----------------------+\n",
    "           |\n",
    "+----------------------+\n",
    "|    Average Pooling   |\n",
    "|      2x4 kernel      |\n",
    "+----------------------+\n",
    "           |\n",
    "+----------------------+\n",
    "|     Convolution      |\n",
    "|    36@ 5x5 kernel    |\n",
    "+----------------------+\n",
    "           |\n",
    "+----------------------+\n",
    "|     Convolution      |\n",
    "|    48@ 5x5 kernel    |\n",
    "+----------------------+\n",
    "           |\n",
    "+----------------------+\n",
    "|     Max Pooling      |\n",
    "|      2x2 kernel      |\n",
    "+----------------------+\n",
    "           |\n",
    "     +----------+\n",
    "     |   RELU   |\n",
    "     +----------+\n",
    "           |\n",
    "    +-------------+\n",
    "    |   Dropout   |\n",
    "    +-------------+\n",
    "           |\n",
    "+----------------------+\n",
    "|     Convolution      |\n",
    "|    64@ 3x3 kernel    |\n",
    "+----------------------+\n",
    "           |\n",
    "+----------------------+\n",
    "|     Convolution      |\n",
    "|    64@ 3x3 kernel    |\n",
    "+----------------------+\n",
    "           |\n",
    "+----------------------+\n",
    "|     Max Pooling      |\n",
    "|      2x2 kernel      |\n",
    "+----------------------+\n",
    "           |\n",
    "     +----------+\n",
    "     |   RELU   |\n",
    "     +----------+\n",
    "           |\n",
    "    +-------------+\n",
    "    |   Dropout   |\n",
    "    +-------------+\n",
    "           |\n",
    "    +-------------+\n",
    "    |   Flatten   |\n",
    "    +-------------+\n",
    "           |\n",
    " +---------------------+\n",
    " |   Fully connected   |\n",
    " |    100 with RELU    |\n",
    " +---------------------+\n",
    "           |\n",
    "    +-------------+\n",
    "    |   Dropout   |\n",
    "    +-------------+\n",
    "           |\n",
    " +---------------------+\n",
    " |   Fully connected   |\n",
    " |     50 with RELU    |\n",
    " +---------------------+\n",
    "           |\n",
    "    +-------------+\n",
    "    |   Dropout   |\n",
    "    +-------------+\n",
    "           |\n",
    " +---------------------+\n",
    " |   Fully connected   |\n",
    " |     10 with RELU    |\n",
    " +---------------------+\n",
    "           |\n",
    "    +-------------+\n",
    "    |   Dropout   |\n",
    "    +-------------+\n",
    "           |\n",
    " +---------------------+\n",
    " |   Fully connected   |\n",
    " |     1 with Tanh     |\n",
    " +---------------------+\n",
    "           |\n",
    "    +--------------+\n",
    "    |   Output 1   |\n",
    "    +--------------+\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### 3. Is the creation of the training dataset and training process documented?\n",
    "\n",
    "The training process is just in the solution design and training data chosen section.  \n",
    "Here is the hard positions where I've run multiple times:\n",
    "\n",
    "![Hard Position](notebook_images/hard1.png)\n",
    "![Hard Position](notebook_images/hard2.png)\n",
    "![Hard Position](notebook_images/hard3.png)\n",
    "\n",
    "\n",
    "## Simulation\n",
    "\n",
    "### 1. Is the car able to navigate correctly on test data?\n",
    "\n",
    "Please look at the `video.mp4`, or run the drive code with simulator on 640x480, Fastest mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Code\n",
    "\n",
    "### model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.misc import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Lambda\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Cropping2D, AveragePooling2D\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# command line flags\n",
    "try:\n",
    "    flags\n",
    "except Exception:\n",
    "    flags = tf.app.flags\n",
    "    FLAGS = flags.FLAGS\n",
    "\n",
    "    flags.DEFINE_string('data_dir', 'dataset', 'Directory of the dataset and driving log.')\n",
    "    flags.DEFINE_string('camera_correction', 0.15, 'Steering correction for the side camera images.')\n",
    "    flags.DEFINE_string('batch_size', 64, 'Batch_size of training.')\n",
    "    flags.DEFINE_string('epoch', 3, 'Epoch of training.')\n",
    "    flags.DEFINE_string('model', 'model.h5', 'Saved model file.')\n",
    "\n",
    "\n",
    "with open(os.path.join(FLAGS.data_dir, 'driving_log.csv'), 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    samples = []\n",
    "    for row in reader:\n",
    "        # Drop half of 0 steering samples\n",
    "        if float(row[6]) != 0 and random.random() < 0.5:\n",
    "            samples.append(row)\n",
    "\n",
    "# Split data set to train and validation set\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "\n",
    "def generator(samples, batch_size=FLAGS.batch_size):\n",
    "    def process_angle(angle, speed):\n",
    "        \"\"\"\n",
    "        All the angles are between -1.2 to 1.2, cut them to [-1, 1] one hot data.\n",
    "        And I have also increase the angle when I have speed down to pass the curve.\n",
    "        \"\"\"\n",
    "            \n",
    "        if angle > 1.0:\n",
    "            return 1.0\n",
    "        elif angle < -1.0:\n",
    "            return -1.0\n",
    "        else:\n",
    "            return angle\n",
    "\n",
    "    def fix_path(path):\n",
    "        \"\"\" Because I've recoed the data in Windows, so need fix the image path in the log file. \"\"\"\n",
    "        path = path.strip()\n",
    "        path = path[path.find('IMG'):]\n",
    "        path = os.path.join(*path.split('\\\\'))\n",
    "        return path\n",
    "\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset + batch_size]\n",
    "\n",
    "            images = []\n",
    "            actions = []\n",
    "            for batch_sample in batch_samples:\n",
    "                speed = float(row[6])\n",
    "                steering_center_angle = float(row[3])\n",
    "\n",
    "                img_center = imread(os.path.join(FLAGS.data_dir, fix_path(row[0])))\n",
    "                img_left = imread(os.path.join(FLAGS.data_dir, fix_path(row[1])))\n",
    "                img_right = imread(os.path.join(FLAGS.data_dir, fix_path(row[2])))\n",
    "                \n",
    "                # Add images, fliped images and actions to data set\n",
    "                images.extend([img_center, img_left, img_right])\n",
    "                images.extend([np.fliplr(img_center), np.fliplr(img_left), np.fliplr(img_right)])\n",
    "                actions.extend([\n",
    "                    process_angle(steering_center_angle, speed),\n",
    "                    process_angle(steering_center_angle + FLAGS.camera_correction, speed),\n",
    "                    process_angle(steering_center_angle - FLAGS.camera_correction, speed)\n",
    "                ])\n",
    "                actions.extend([\n",
    "                    process_angle(-steering_center_angle, speed),\n",
    "                    process_angle(-steering_center_angle - FLAGS.camera_correction, speed),\n",
    "                    process_angle(-steering_center_angle + FLAGS.camera_correction, speed)\n",
    "                ])\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(actions).reshape(-1, 1)\n",
    "            yield shuffle(X_train, y_train)\n",
    "\n",
    "                                        \n",
    "def CNN():\n",
    "    \"\"\" My CNN based on VGGNet. \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Cropping2D(cropping=((64, 24), (0,0)), input_shape=(160, 320, 3)))\n",
    "    model.add(Lambda(lambda x: (x / 127.5) - 1, input_shape=(72, 320, 3)))\n",
    "    # input: 72x320 images with 3 channels\n",
    "    # Using one average pooling to change the image size smaller\n",
    "    model.add(AveragePooling2D(pool_size=(2, 4)))\n",
    "\n",
    "    # this applies 32 convolution filters of size 3x3 each.\n",
    "    model.add(Convolution2D(36, 5, 5, border_mode='valid', input_shape=(72, 320, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(48, 5, 5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('tanh'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=FLAGS.batch_size)\n",
    "validation_generator = generator(validation_samples, batch_size=FLAGS.batch_size)\n",
    "\n",
    "if os.path.exists(FLAGS.model):\n",
    "    model = load_model(FLAGS.model)\n",
    "else:\n",
    "    model = CNN()\n",
    "    \n",
    "# Because I've flip all the image and 3 directions, so the size of data set must be multiple by 6\n",
    "history_object = model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=len(train_samples) * 6,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=len(validation_samples) * 6,\n",
    "    nb_epoch=FLAGS.epoch,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# Save the model\n",
    "model.save(FLAGS.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drive.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import base64\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import socketio\n",
    "import eventlet\n",
    "import eventlet.wsgi\n",
    "from PIL import Image\n",
    "from flask import Flask\n",
    "from io import BytesIO\n",
    "\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "from keras import __version__ as keras_version\n",
    "\n",
    "sio = socketio.Server()\n",
    "app = Flask(__name__)\n",
    "model = None\n",
    "prev_image_array = None\n",
    "\n",
    "\n",
    "class SimplePIController:\n",
    "    def __init__(self, Kp, Ki):\n",
    "        self.Kp = Kp\n",
    "        self.Ki = Ki\n",
    "        self.set_point = 0.\n",
    "        self.error = 0.\n",
    "        self.integral = 0.\n",
    "        self.last_steering_angle = 0.\n",
    "\n",
    "    def set_desired(self, desired):\n",
    "        self.set_point = desired\n",
    "\n",
    "    def update(self, measurement, steering_angle):\n",
    "        # proportional error\n",
    "        self.error = self.set_point - measurement\n",
    "\n",
    "        # integral error\n",
    "        self.integral += self.error\n",
    "        \n",
    "        # smooth steering\n",
    "        steering_angle = self.last_steering_angle * 0.5 + steering_angle\n",
    "        self.last_steering_angle = steering_angle\n",
    "\n",
    "        return self.Kp * self.error + self.Ki * self.integral, steering_angle\n",
    "\n",
    "\n",
    "controller = SimplePIController(0.05, 0.002)\n",
    "set_speed = 15\n",
    "controller.set_desired(set_speed)\n",
    "\n",
    "\n",
    "@sio.on('telemetry')\n",
    "def telemetry(sid, data):\n",
    "    if data:\n",
    "        # The current steering angle of the car\n",
    "        steering_angle = data[\"steering_angle\"]\n",
    "        # The current throttle of the car\n",
    "        throttle = data[\"throttle\"]\n",
    "        # The current speed of the car\n",
    "        speed = data[\"speed\"]\n",
    "        # The current image from the center camera of the car\n",
    "        imgString = data[\"image\"]\n",
    "        image = Image.open(BytesIO(base64.b64decode(imgString)))\n",
    "        image_array = np.asarray(image)\n",
    "        result = model.predict(image_array[None, :, :, :], batch_size=1)\n",
    "        predict_steering_angle = result[0][0]\n",
    "\n",
    "        throttle, steering_angle = controller.update(float(speed), predict_steering_angle)\n",
    "        if abs(steering_angle) > 0.05:\n",
    "            steering_angle = steering_angle * 2\n",
    "            controller.set_desired(set_speed / 2)\n",
    "        else:\n",
    "            controller.set_desired(set_speed)\n",
    "\n",
    "        print(predict_steering_angle, steering_angle, throttle)\n",
    "        send_control(steering_angle, throttle)\n",
    "\n",
    "        # save frame\n",
    "        if args.image_folder != '':\n",
    "            timestamp = datetime.utcnow().strftime('%Y_%m_%d_%H_%M_%S_%f')[:-3]\n",
    "            image_filename = os.path.join(args.image_folder, timestamp)\n",
    "            image.save('{}.jpg'.format(image_filename))\n",
    "    else:\n",
    "        # NOTE: DON'T EDIT THIS.\n",
    "        sio.emit('manual', data={}, skip_sid=True)\n",
    "\n",
    "\n",
    "@sio.on('connect')\n",
    "def connect(sid, environ):\n",
    "    print(\"connect \", sid)\n",
    "    send_control(0, 0)\n",
    "\n",
    "\n",
    "def send_control(steering_angle, throttle):\n",
    "    sio.emit(\n",
    "        \"steer\",\n",
    "        data={\n",
    "            'steering_angle': steering_angle.__str__(),\n",
    "            'throttle': throttle.__str__()\n",
    "        },\n",
    "        skip_sid=True)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Remote Driving')\n",
    "    parser.add_argument(\n",
    "        'model',\n",
    "        type=str,\n",
    "        help='Path to model h5 file. Model should be on the same path.'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        'image_folder',\n",
    "        type=str,\n",
    "        nargs='?',\n",
    "        default='',\n",
    "        help='Path to image folder. This is where the images from the run will be saved.'\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # check that model Keras version is same as local Keras version\n",
    "    f = h5py.File(args.model, mode='r')\n",
    "    model_version = f.attrs.get('keras_version')\n",
    "    keras_version = str(keras_version).encode('utf8')\n",
    "\n",
    "    if model_version != keras_version:\n",
    "        print('You are using Keras version ', keras_version,\n",
    "              ', but the model was built using ', model_version)\n",
    "\n",
    "    model = load_model(args.model)\n",
    "\n",
    "    if args.image_folder != '':\n",
    "        print(\"Creating image folder at {}\".format(args.image_folder))\n",
    "        if not os.path.exists(args.image_folder):\n",
    "            os.makedirs(args.image_folder)\n",
    "        else:\n",
    "            shutil.rmtree(args.image_folder)\n",
    "            os.makedirs(args.image_folder)\n",
    "        print(\"RECORDING THIS RUN ...\")\n",
    "    else:\n",
    "        print(\"NOT RECORDING THIS RUN ...\")\n",
    "\n",
    "    # wrap Flask application with engineio's middleware\n",
    "    app = socketio.Middleware(sio, app)\n",
    "\n",
    "    # deploy as an eventlet WSGI server\n",
    "    eventlet.wsgi.server(eventlet.listen(('', 4567)), app)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:CarND]",
   "language": "python",
   "name": "conda-env-CarND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
